<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="初步利用开源facenet框架和已有模型进行人脸识别测试"><meta name="keywords" content="training,tensorflow"><meta name="author" content="Yunfei Zhang"><meta name="copyright" content="Yunfei Zhang"><title>初步利用开源facenet框架和已有模型进行人脸识别测试 | grassbloomy</title><link rel="shortcut icon" href="/favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><link rel="manifest" href="/manifest.json"><link rel="manifest" href="/manifest.json"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#配置环境介绍"><span class="toc-number">1.</span> <span class="toc-text">配置环境介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GitHub上clone-facenet项目"><span class="toc-number">2.</span> <span class="toc-text">GitHub上clone facenet项目</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#下载LFW测试集"><span class="toc-number">3.</span> <span class="toc-text">下载LFW测试集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#对LFW测试集做预处理"><span class="toc-number">4.</span> <span class="toc-text">对LFW测试集做预处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#装载训练模型"><span class="toc-number">5.</span> <span class="toc-text">装载训练模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#运行测试"><span class="toc-number">6.</span> <span class="toc-text">运行测试</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">Yunfei Zhang</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">5</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">3</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">1</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://i.loli.net/2019/07/06/5d2043345129b66140.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">grassbloomy</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">初步利用开源facenet框架和已有模型进行人脸识别测试</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-07-14</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/技术/">技术</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>tensorflow-gpu这些装上了一直没有用到，现在对其做一个简单的人脸识别测试。<br><a id="more"></a></p>
<h2 id="配置环境介绍"><a href="#配置环境介绍" class="headerlink" title="配置环境介绍"></a>配置环境介绍</h2><ul>
<li>tensorflow-gpu 1.13</li>
<li>scipy</li>
<li>scikit-learn</li>
<li>opencv-python</li>
<li>h5py</li>
<li>matplotlib</li>
<li>Pillow</li>
<li>requests</li>
<li>psutil</li>
</ul>
<h2 id="GitHub上clone-facenet项目"><a href="#GitHub上clone-facenet项目" class="headerlink" title="GitHub上clone facenet项目"></a>GitHub上clone facenet项目</h2><p><code>git clone https://github.com/davidsandberg/facenet.git</code></p>
<h2 id="下载LFW测试集"><a href="#下载LFW测试集" class="headerlink" title="下载LFW测试集"></a>下载LFW测试集</h2><p>LFW 是由美国马萨诸塞大学阿姆斯特分校计算机视觉实验室整理的。它包含13233张图片，共5749人，其中4096人只有一张图片，1680人的图片多余一张，每张图片尺寸是250x250。<br>将测试集保存至 facenet/data/lfw_data/lfw 目录中.<br>可以在大学网页 (<a href="http://vis-www.cs.umass.edu/lfw/" target="_blank" rel="noopener">http://vis-www.cs.umass.edu/lfw/</a>)  -&gt;Menu-&gt;Download-&gt;All images as gzipped tar file 中下载<br>也可以在facenet官方给出的地址(<a href="http://vis-www.cs.umass.edu/lfw/lfw.tgz)下载" target="_blank" rel="noopener">http://vis-www.cs.umass.edu/lfw/lfw.tgz)下载</a></p>
<h2 id="对LFW测试集做预处理"><a href="#对LFW测试集做预处理" class="headerlink" title="对LFW测试集做预处理"></a>对LFW测试集做预处理</h2><p>由于测试集中的图片尺寸是250x250，而facenet要求图片尺寸为160x160，所以需要批量进行处理把尺寸改为160x160<br>这里在 facenet/data/lfw_data/ 目录下创建lfw_160文件夹，用于输出。<br>facenet中已经写好了一个处理尺寸的py文件，路径为 facenet/src/align/align_dataset_mtcnn.py ，运行py程序时需要加上输入和输出路径<br>这里需要先把align_dataset_mtcnn.py文件移动到上一级，即src文件夹中<br>在命令行中的调用方法：<br><code>python align_dataset_mtcnn.py facenet/data/lfw_data/lfw facenet/data/lfw_data/lfw_160 --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25</code><br>我在这里遇到报错：ValueError: Object arrays cannot be loaded when allow_pickle=False，经过查找发现这是numpy 1.16.3 版本问题，最终在npy.io文件中的load函数中加上了allow_pickle=True，问题解决<br>经过一段时间，输出完毕。<br><img src="https://i.loli.net/2019/07/14/5d2b12cf615e154217.png" alt="图片裁剪.png"></p>
<h2 id="装载训练模型"><a href="#装载训练模型" class="headerlink" title="装载训练模型"></a>装载训练模型</h2><p>如前面所说，这是一个测试模型的库，你可以检测自己的训练模型好坏，也可以检测别人的，这里从下载预先训练好的模型来运行测试，链接给出：<a href="https://drive.google.com/file/d/1EXPBSXwTaqrSC0OhUdXNmKSh9qJUQ55-/view?usp=drive_open" target="_blank" rel="noopener">https://drive.google.com/file/d/1EXPBSXwTaqrSC0OhUdXNmKSh9qJUQ55-/view?usp=drive_open</a> （谷歌云）<br>百度网盘：链接: <a href="https://pan.baidu.com/s/1DGCVRQl5_aYKgczglVKJlQ" target="_blank" rel="noopener">https://pan.baidu.com/s/1DGCVRQl5_aYKgczglVKJlQ</a> 提取码: 2pgx<br>下载完毕解压后，将模型放至 facenet/src/models 目录下。</p>
<h2 id="运行测试"><a href="#运行测试" class="headerlink" title="运行测试"></a>运行测试</h2><p>使用 facenet/src/validate_on_lfw.py 进行测试<br><code>python validate_on_lfw.py facenet/data/lfw_data/lfw_160 models/20180402-114759 --distance_metric 1 --use_flipped_images --subtract_mean --use_fixed_image_standardization</code><br>给出参数列表：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">'lfw_dir'</span>, type=str,</span><br><span class="line">       help=<span class="string">'Path to the data directory containing aligned LFW face patches.'</span>)</span><br><span class="line">   parser.add_argument(<span class="string">'--lfw_batch_size'</span>, type=int,</span><br><span class="line">       help=<span class="string">'Number of images to process in a batch in the LFW test set.'</span>, default=<span class="number">100</span>)</span><br><span class="line">   parser.add_argument(<span class="string">'model'</span>, type=str, </span><br><span class="line">       help=<span class="string">'Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file'</span>)</span><br><span class="line">   parser.add_argument(<span class="string">'--image_size'</span>, type=int,</span><br><span class="line">       help=<span class="string">'Image size (height, width) in pixels.'</span>, default=<span class="number">160</span>)</span><br><span class="line">   parser.add_argument(<span class="string">'--lfw_pairs'</span>, type=str,</span><br><span class="line">       help=<span class="string">'The file containing the pairs to use for validation.'</span>, default=<span class="string">'facenet/data/pairs.txt'</span>)</span><br><span class="line">   parser.add_argument(<span class="string">'--lfw_nrof_folds'</span>, type=int,</span><br><span class="line">       help=<span class="string">'Number of folds to use for cross validation. Mainly used for testing.'</span>, default=<span class="number">10</span>)</span><br><span class="line">   parser.add_argument(<span class="string">'--distance_metric'</span>, type=int,</span><br><span class="line">       help=<span class="string">'Distance metric  0:euclidian, 1:cosine similarity.'</span>, default=<span class="number">0</span>)</span><br><span class="line">   parser.add_argument(<span class="string">'--use_flipped_images'</span>, </span><br><span class="line">       help=<span class="string">'Concatenates embeddings for the image and its horizontally flipped counterpart.'</span>, action=<span class="string">'store_true'</span>)</span><br><span class="line">   parser.add_argument(<span class="string">'--subtract_mean'</span>, </span><br><span class="line">       help=<span class="string">'Subtract feature mean before calculating distance.'</span>, action=<span class="string">'store_true'</span>)</span><br><span class="line">   parser.add_argument(<span class="string">'--use_fixed_image_standardization'</span>, </span><br><span class="line">       help=<span class="string">'Performs fixed standardization of images.'</span>, action=<span class="string">'store_true'</span>)</span><br></pre></td></tr></table></figure></p>
<p>参数依次给出了测试集位置，模型位置，使用余弦相似度量，计算图像的翻转版本…<br>最终给出结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: 0.99650+-0.00302</span><br><span class="line">Validation rate: 0.98567+-0.00967 @ FAR=0.00100</span><br><span class="line">Area Under Curve (AUC): 1.000</span><br><span class="line">Equal Error Rate (EER): 0.004</span><br></pre></td></tr></table></figure></p>
<p>遇到了2个问题</p>
<ol>
<li><p>运行中报错：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;validate_on_lfw.py&quot;, line 164, in &lt;module&gt;</span><br><span class="line">	main(parse_arguments(sys.argv[1:]))</span><br><span class="line">  File &quot;validate_on_lfw.py&quot;, line 73, in main</span><br><span class="line">	facenet.load_model(args.model, input_map=input_map)</span><br><span class="line">  File &quot;G:\facenet\src\facenet.py&quot;, line 381, in load_model</span><br><span class="line">	saver = tf.train.import_meta_graph(os.path.join(model_exp, meta_file), input_map=input_map)</span><br><span class="line">  File &quot;C:\Users\User\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\training\saver.py&quot;, line 1435, in import_meta_graph</span><br><span class="line">	meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]</span><br><span class="line">  File &quot;C:\Users\User\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\training\saver.py&quot;, line 1457, in _import_meta_graph_with_return_elements</span><br><span class="line">	**kwargs))</span><br><span class="line">  File &quot;C:\Users\User\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\framework\meta_graph.py&quot;, line 841, in import_scoped_meta_graph_with_return_elements</span><br><span class="line">	proto, import_scope=scope_to_prepend_to_names))</span><br><span class="line">  File &quot;C:\Users\User\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\ops\control_flow_ops.py&quot;, line 1794, in from_proto</span><br><span class="line">	ret = CondContext(context_def=context_def, import_scope=import_scope)</span><br><span class="line">  File &quot;C:\Users\User\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\ops\control_flow_ops.py&quot;, line 1703, in __init__</span><br><span class="line">	self._init_from_proto(context_def, import_scope=import_scope)</span><br><span class="line">  File &quot;C:\Users\User\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\ops\control_flow_ops.py&quot;, line 1735, in _init_from_proto</span><br><span class="line">	values_def=context_def.values_def, import_scope=import_scope)</span><br><span class="line">  File &quot;C:\Users\User\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\ops\control_flow_ops.py&quot;, line 1508, in __init__</span><br><span class="line">	self._init_values_from_proto(values_def, import_scope=import_scope)</span><br><span class="line">  File &quot;C:\Users\User\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\ops\control_flow_ops.py&quot;, line 1540, in _init_values_from_proto</span><br><span class="line">	g.as_graph_element(op)._set_control_flow_context(self)</span><br><span class="line">  File &quot;C:\Users\User\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\framework\ops.py&quot;, line 3478, in as_graph_element</span><br><span class="line">	return self._as_graph_element_locked(obj, allow_tensor, allow_operation)</span><br><span class="line">  File &quot;C:\Users\User\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\framework\ops.py&quot;, line 3538, in _as_graph_element_locked</span><br><span class="line">	&quot;graph.&quot; % repr(name))</span><br><span class="line">KeyError: &quot;The name &apos;decode_image/cond_jpeg/is_png&apos; refers to an Operation not in the graph.&quot;</span><br></pre></td></tr></table></figure>
<p> 经过搜索，发现解决思路：</p>
<blockquote>
<p>Your issue can be solved by adding a name scope around the entire facenet.create_input_pipeline function.<br> The bug is because the code uses import_meta_graph to create the graph on top of an existing graph. This usage is error-prone due to potential name conflicts.</p>
</blockquote>
<p> 最终在在facenet.py中的create_input_pipeline函数下添加<br> <code>with tf.name_scope(&quot;tempscope&quot;):</code></p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">def create_input_pipeline(input_queue, image_size, nrof_preprocess_threads, batch_size_placeholder):</span><br><span class="line">	with tf.name_scope(&quot;tempscope&quot;):</span><br><span class="line">		images_and_labels_list = []</span><br><span class="line">		for _ in range(nrof_preprocess_threads):</span><br><span class="line">			filenames, label, control = input_queue.dequeue()</span><br><span class="line">			images = []</span><br><span class="line">			for filename in tf.unstack(filenames):</span><br><span class="line">				file_contents = tf.read_file(filename)</span><br><span class="line">				image = tf.image.decode_image(file_contents, 3)</span><br><span class="line">				image = tf.cond(get_control_flag(control[0], RANDOM_ROTATE),</span><br><span class="line">								lambda:tf.py_func(random_rotate_image, [image], tf.uint8), </span><br><span class="line">								lambda:tf.identity(image))</span><br><span class="line">				image = tf.cond(get_control_flag(control[0], RANDOM_CROP), </span><br><span class="line">								lambda:tf.random_crop(image, image_size + (3,)), </span><br><span class="line">								lambda:tf.image.resize_image_with_crop_or_pad(image, image_size[0], image_size[1]))</span><br><span class="line">				image = tf.cond(get_control_flag(control[0], RANDOM_FLIP),</span><br><span class="line">								lambda:tf.image.random_flip_left_right(image),</span><br><span class="line">								lambda:tf.identity(image))</span><br><span class="line">				image = tf.cond(get_control_flag(control[0], FIXED_STANDARDIZATION),</span><br><span class="line">								lambda:(tf.cast(image, tf.float32) - 127.5)/128.0,</span><br><span class="line">								lambda:tf.image.per_image_standardization(image))</span><br><span class="line">				image = tf.cond(get_control_flag(control[0], FLIP),</span><br><span class="line">								lambda:tf.image.flip_left_right(image),</span><br><span class="line">								lambda:tf.identity(image))</span><br><span class="line">				#pylint: disable=no-member</span><br><span class="line">				image.set_shape(image_size + (3,))</span><br><span class="line">				images.append(image)</span><br><span class="line">			images_and_labels_list.append([images, label])</span><br><span class="line"></span><br><span class="line">		image_batch, label_batch = tf.train.batch_join(</span><br><span class="line">			images_and_labels_list, batch_size=batch_size_placeholder, </span><br><span class="line">			shapes=[image_size + (3,), ()], enqueue_many=True,</span><br><span class="line">			capacity=4 * nrof_preprocess_threads * 100,</span><br><span class="line">			allow_smaller_final_batch=True)</span><br><span class="line">	</span><br><span class="line">	return image_batch, label_batch</span><br></pre></td></tr></table></figure>
<p> 问题解决。</p>
</li>
<li><p>运行完程序后报错</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">2019-07-14 15:30:33.575898: W tensorflow/core/kernels/queue_base.cc:285] _2_FIFOQueueV2_1: Skipping cancelled dequeue attempt with queue not closed</span><br><span class="line">2019-07-14 15:30:33.582318: W tensorflow/core/kernels/queue_base.cc:285] _2_FIFOQueueV2_1: Skipping cancelled dequeue attempt with queue not closed</span><br><span class="line">2019-07-14 15:30:33.590200: W tensorflow/core/kernels/queue_base.cc:285] _2_FIFOQueueV2_1: Skipping cancelled dequeue attempt with queue not closed</span><br><span class="line">2019-07-14 15:30:33.596049: W tensorflow/core/kernels/queue_base.cc:285] _2_FIFOQueueV2_1: Skipping cancelled dequeue attempt with queue not closed</span><br><span class="line">2019-07-14 15:30:33.600492: W tensorflow/core/kernels/queue_base.cc:277] _4_input_producer: Skipping cancelled enqueue attempt with queue not closed</span><br><span class="line">2019-07-14 15:30:33.609625: W tensorflow/core/kernels/queue_base.cc:285] _0_FIFOQueueV2: Skipping cancelled dequeue attempt with queue not closed</span><br><span class="line">2019-07-14 15:30:33.616131: W tensorflow/core/kernels/queue_base.cc:285] _0_FIFOQueueV2: Skipping cancelled dequeue attempt with queue not closed</span><br><span class="line">2019-07-14 15:30:33.620320: W tensorflow/core/kernels/queue_base.cc:285] _0_FIFOQueueV2: Skipping cancelled dequeue attempt with queue not closed</span><br><span class="line">2019-07-14 15:30:33.627709: W tensorflow/core/kernels/queue_base.cc:285] _0_FIFOQueueV2: Skipping cancelled dequeue attempt with queue not closed</span><br></pre></td></tr></table></figure>
<p> 网上搜索表明这或许与tf会忽略非主线程的运行出错有关，但更多倾向于这是版本错误，这些错误可以忽略，至少现在这些错误没有造成什么负面影响。</p>
</li>
</ol>
</div></article><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/training/">training</a><a class="post-meta__tags" href="/tags/tensorflow/">tensorflow</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2019/09/17/hadoop和hbase安装遇到的坑/"><i class="fa fa-chevron-left">  </i><span>hadoop和hbase安装遇到的坑</span></a></div><div class="next-post pull-right"><a href="/2019/07/13/OCR/"><span>OCR</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://i.loli.net/2019/07/06/5d2043345129b66140.png)"><div class="layout" id="footer"><div class="copyright">&copy;2019 By Yunfei Zhang</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>